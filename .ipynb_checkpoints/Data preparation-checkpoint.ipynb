{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "Contents:\n",
    "- Add names. (done)\n",
    "- Remove outliers - people who have probably incorrectly answered questions and people who have randomly answered questions. (done - check errors)\n",
    "- Data preparation for Together Apart - deciding and selecting columns that are relevant for friend-finding. (done)\n",
    "- Final cleaning - analysing and solving any final issues; exporting the final dataframe as a separate csv. (done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalisation, Recommender System, and Data Viz\n",
    "Contents:\n",
    "- User recommendation - recommender system for matching users with 10 others based on their interest registered through the questionaire registration form. (almost done - needs updating and a check)\n",
    "- Data visualisation - view for user to aid understanding of their match percentage and a view for the developers to enable monitoring. (to do)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - Add names\n",
    "The Young People Survey dataset is anonymous. For our app, we will have the participants enter their name into the questionnaire. To make this dataset mimic the dataset we will create in our app, we need to give the participants names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the  data and store as a Pandas dateframe\n",
    "df = pd.read_csv(\"responses.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column labels\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to know which participants are male and which are female, so that we can add names of the correct gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of males, females, and unknown gender\n",
    "n_male = (df['Gender'] == 'male').sum()\n",
    "n_female = (df['Gender'] == 'female').sum()\n",
    "n_unknown = df['Gender'].isnull().sum()\n",
    "print(n_male, n_female, n_unknown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 6 participants who did not give their gender, we'll give these people male names as there are fewer males in the dataset.\n",
    "\n",
    "We've created a list of male names and a list of female names which we can import and clean up as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import name lists\n",
    "df_female_names = pd.read_csv('female_names.csv')[:n_female]\n",
    "df_male_names = pd.read_csv('male_names.csv')[:n_male + n_unknown]\n",
    "\n",
    "# remove non-ascii characters which have occurred because the names were copied from a website.\n",
    "df_male_names['Name'] = df_male_names['Name'].apply(lambda x: x.replace('\\xa0', ' '))\n",
    "df_female_names['Name'] = df_female_names['Name'].apply(lambda x: x.replace('\\xa0', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add new column to main dataframe for name\n",
    "df['Name'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the indices of the male name dataframe to be the indices of the males (and unknowns) in the\n",
    "# main dataframe.\n",
    "df_male_names = df_male_names.set_index(df.index[(df['Gender'] == 'male') | df['Gender'].isnull()])\n",
    "\n",
    "# Do the same for females.\n",
    "df_female_names = df_female_names.set_index(df.index[(df['Gender'] == 'female')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add names into main dataframe.\n",
    "df['Name'] = df_male_names\n",
    "df.loc[df['Gender'] == 'female', 'Name'] = df_female_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a column of names with the appropriate genders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the gender and names of the last few rows.\n",
    "df[['Gender', 'Name']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - Remove outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore data for abnormal values. Only the Age, Height, Weight, and Number of siblings questions allowed the participant to enter any value. So let's check the extreme values of these columns to see if there are any anomolies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Age', 'Height', 'Weight', 'Number of siblings']].agg(['min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age and number of siblings look ok. The height is measured in cm and the weight in kg, so the min height and max weight look like errors. Let's look more closely at these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Height'] < 120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That 62cm height looks like an error, given that she weighs 55kg. Let's replace it with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[676,'Height'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Weight'] > 130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There are very few people with a weight of 150kg or more. The participants may have misread the units, thinking they were entering 150lb instead. Let's replace these extreme values with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[885,'Weight'] = np.NaN\n",
    "df.loc[992,'Weight'] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's check whether there are any people who have incorrectly answered whether they are an only child and how many siblings they have. If someone is an only child, they have no siblings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Only child', 'Number of siblings']][(df['Only child'] == 'yes') & (df['Number of siblings'] >= 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 95 people who either incorrectly answered whether they are an only child or the number of siblings they have. Let's change these values to NaN for these participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_error = df[['Only child', 'Number of siblings']][(df['Only child'] == 'yes') & (df['Number of siblings'] >= 1)].index\n",
    "df.loc[i_error, ['Only child', 'Number of siblings']] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's identify people who are likely to have randomly answered the questions. For this, we can use the [local outlier factor algorithm](https://en.wikipedia.org/wiki/Local_outlier_factor). TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_float_only = df.dropna().loc[:, df.dtypes == float]\n",
    "df_float_only_normalized = (df_float_only - df_float_only.min())/(df_float_only.max() - df_float_only.min())\n",
    "\n",
    "\n",
    "# fit the model for outlier detection\n",
    "clf = LocalOutlierFactor(n_neighbors=20)\n",
    "\n",
    "clf.fit_predict(df_float_only_normalized)\n",
    "X_scores = clf.negative_outlier_factor_\n",
    "\n",
    "# # np.where(X_scores < -1.2)\n",
    "\n",
    "df_dropna = df.dropna()\n",
    "df_dropna['LOF score'] = X_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropna.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_dropna[df_dropna['LOF score'] < -1.4].iloc[0].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - Data preparation for Together Apart\n",
    "In this section, we decide on the columns that are relevant for friend-finding.We also get the data ready to match with the Together Apart registration form/questionaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing and analysing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the columns\n",
    "\n",
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shape of the dataset\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the mean value, type, and length of some columns (overwriten)\n",
    "\n",
    "df['Music'].mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deciding on the columns we'll use\n",
    "\n",
    "For the purposes of this project we decided to continue with the following columns (please see the lists below).\n",
    "\n",
    "In the registration form they will be grouped in two categories: \"Activities\" and \"Interesting Subjects\".\n",
    "\n",
    "The form will provide a 1 to 5 linkert scale for each subject (which is a column name in this dataset), where 1 means \"not interested\" and 5 - \"very interested\". The user will be able to choose the level of their interest, to then match up with someone, based on similarities of what they would like to do with their new buddy.\n",
    "\n",
    "\n",
    "#### Activities (Let's Do This - Together Apart) (I am looking for an activity buddy.)\n",
    "* Dancing\n",
    "* Singing (\"Musical instruments\" in this dataset)\n",
    "* Writing\n",
    "* Meditation (\"Passive sport\" in this dataset)\n",
    "* Playing games (\"Fun with friends\" in this dataset)\n",
    "* Active sports (such as yoga; \"Active sport\" in this dataset)\n",
    "* Being creative (\"Art exhibition\" in this dataset)\n",
    "* Acting (\"Theatre\" in this dataset)\n",
    "* Cooking (\"Healthy eating\" in this dataset)\n",
    "* Gardening\n",
    "* Pets\n",
    "\n",
    "#### Interesting Subjects (Let's Talk - Together Apart) (I would like to talk about this with a buddy.)\n",
    "* Music\n",
    "* Movies\n",
    "* Reading\n",
    "* Foreign languages\n",
    "* Daily events\n",
    "* Celebrities\n",
    "* Science and technology\n",
    "* Future goals (\"Thinking ahead\" in this dataset)\n",
    "* Sharing my past (\"Changing the past\" in this dataset)\n",
    "* Dreams\n",
    "* Loneliness\n",
    "* Health\n",
    "* Mental wellbeing (\"Mood swings\" in this dataset)\n",
    "* Life struggles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renamed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the decision above by altering the column names\n",
    "# and saving those changes in a new dataframe: df_col_renamed.\n",
    "\n",
    "df_col_renamed = df.rename(columns={'Musical instruments': 'Singing',\n",
    "                           'Passive sport': 'Meditation',\n",
    "                           'Fun with friends': 'Playing games',\n",
    "                           'Active sport': 'Active sports',\n",
    "                           'Art exhibitions': 'Being creative',\n",
    "                           'Theatre': 'Acting',\n",
    "                           'Healthy eating': 'Cooking',\n",
    "                           'Thinking ahead': 'Future goals',\n",
    "                           'Changing the past': 'Sharing my past',\n",
    "                           'Mood swings': 'Mental wellbeing'})\n",
    "\n",
    "print(df_col_renamed.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final shortened dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here I wanted to drop the unused columns and save the final vs into a new file\n",
    "# but soon realised it would be much faster to just create a new df with listed columns (ta - for together apart :D) \n",
    "\n",
    "df_ta = df_col_renamed[['Name', 'Dancing', 'Singing', 'Writing', 'Meditation',\n",
    "                        'Playing games', 'Active sports', 'Being creative',\n",
    "                        'Acting', 'Cooking', 'Gardening', 'Pets', 'Music',\n",
    "                        'Movies', 'Reading', 'Foreign languages', 'Daily events',\n",
    "                        'Celebrities', 'Science and technology', 'Future goals',\n",
    "                        'Sharing my past', 'Dreams', 'Loneliness', 'Health', 'Mental wellbeing', 'Life struggles']]\n",
    "\n",
    "print(df_ta.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - Final cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at the full final dataframe - uncomment to prints\n",
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.width', None)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# print(df_ta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking at this dataframe, we can notice some issues that need to be solved:\n",
    "\n",
    "* \"Dreams\" column is of a different type\n",
    "* The dataset contains missing values \n",
    "* \"Name\" column has trailing\n",
    "\n",
    "### Type casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the types of final columns\n",
    "\n",
    "print (df_ta.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Changing the Dreams column to be of float type.\n",
    "\n",
    "df_ta = df_ta.astype({'Dreams': 'float64'})\n",
    "print(df_ta.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation of missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of NaNs\n",
    "\n",
    "df_ta.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing NaNs, with the most frequent value of the columns (axis 0) that contain the missing values:\n",
    "\n",
    "df_ta = df_ta.apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
    "\n",
    "# Checking the number of NaNs after the change\n",
    "\n",
    "df_ta.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trailing removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cleaning up the whitespace in the \"Name\" column\n",
    "\n",
    "df_ta['Name'] = df_ta['Name'].apply(str.strip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Looking at the full final dataframe\n",
    "\n",
    "print(df_ta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shape of the dataset\n",
    "\n",
    "df_ta.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All looks good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merging the final cleaned dataframe (\"df_ta\") with the \"df\" for easier use in future\n",
    "\n",
    "df = df_ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exporting the final version of the dataframe as a .csv file\n",
    "# (commented out so it won't save on another run automatically)\n",
    "\n",
    "#df.to_csv('TA_PreData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "We have 25 subjects that will be used in the registration form and 1010 entries for each that we can already work from to normalise the scores, implement machine learning algoritm to match users and create data visualisation for us and the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# - User recommendation\n",
    "In this section, we use collaborative filtering to recommend users to other users based on the similarity of their interests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns are not numerical. We want to apply collaborative filtering to only the columns that are numerical and relevant to matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cf = df.iloc[:,:140].select_dtypes(include=['float64', 'int64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cf.isnull().sum().sum()/(df.shape[0]*df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proportion of unanswered questions is small, so we should be able to use all the people for the recommender system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Centre each row\n",
    "df_cf_centred = df_cf.sub(df_cf.mean(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cf_centred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill nans with 0.0 (mean of centred rows)\n",
    "df_cf_centred = df_cf_centred.fillna(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "n_neighbors = 10\n",
    "\n",
    "#make an object for the NearestNeighbors Class.\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=n_neighbors, n_jobs=-1)\n",
    "\n",
    "# fit the dataset\n",
    "model_knn.fit(df_cf_centred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distances, indices = model_knn.kneighbors(df_cf_centred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances[:,1:].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(distances == distances[:,1].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices[449,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cf_centred.iloc[[449,453],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aim: write a function where you enter your name and it lists the N best matches, their match score,\n",
    "# plots the match scores, plots the interest trees.\n",
    "\n",
    "def find_matches(index=None, name=None, n=10):\n",
    "    if name is None and index is None:\n",
    "        print('Enter an index or name.')\n",
    "    elif name is None:\n",
    "        name = df.iloc[index]['Name']\n",
    "    elif index is None:\n",
    "        index = list(df[df['Name'] == name].index)[0]\n",
    "    \n",
    "    match_indices = indices[index, 1:]\n",
    "    match_names = list(df.iloc[match_indices]['Name'])\n",
    "    match_distances = list(distances[index, 1:])\n",
    "    \n",
    "    return match_names, match_distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'Sally Abraham'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df[df['Name'] == name].index)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[1,2,3,40]]['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_matches(name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_matches(index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(9)\n",
    "plt.bar(x, (1 - find_matches(index=0)[1])*100)\n",
    "plt.xticks(x, find_matches(index=0)[0], rotation='vertical')\n",
    "plt.ylim([0, 100])\n",
    "plt.xlabel('Top matches')\n",
    "plt.ylabel('Match percentage')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
